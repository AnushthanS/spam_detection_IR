{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from scipy.sparse import save_npz, load_npz\n",
    "from scipy import sparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105199 entries, 0 to 105198\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   label   105199 non-null  int64 \n",
      " 1   text    101072 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./DataSet/combined_data.csv\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ham percentage: 38.98611203528551\n",
      "Spam percentage: 61.0138879647145\n"
     ]
    }
   ],
   "source": [
    "ham_count = data[\"label\"].value_counts()[0]\n",
    "spam_count = data[\"label\"].value_counts()[1]\n",
    "\n",
    "ham_percentage = ham_count / (ham_count + spam_count) * 100\n",
    "spam_percentage = spam_count / (ham_count + spam_count) * 100\n",
    "\n",
    "print(\"Ham percentage:\", ham_percentage)\n",
    "print(\"Spam percentage:\", spam_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in text: 4127\n"
     ]
    }
   ],
   "source": [
    "def check_and_remove_nan(df, column_name):\n",
    "    nan_count = df[column_name].isna().sum()\n",
    "    print(f\"Number of NaN values in {column_name}: {nan_count}\")\n",
    "    df = df.dropna(subset=[column_name])\n",
    "    \n",
    "    return df\n",
    "\n",
    "data = check_and_remove_nan(data, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    101072.000000\n",
      "mean         26.557741\n",
      "std         121.429828\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%          13.000000\n",
      "max       10444.000000\n",
      "Name: text, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def count_non_chars(text):\n",
    "  count = 0\n",
    "  for word in text.split():\n",
    "    if not re.match('[a-zA-Z\\s]', word):\n",
    "      count += 1\n",
    "  return count\n",
    "\n",
    "total_count = data[\"text\"].apply(count_non_chars)\n",
    "print(total_count.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "Plain Text:\n",
      " do you feel the pressure to perform and not rising to the occasion try v ia gr a your anxiety will be a thing of the past and you will be back to your old self \n",
      "\n",
      "\n",
      "After removing punctuations:\n",
      " do you feel the pressure to perform and not rising to the occasion try v ia gr a your anxiety will be a thing of the past and you will be back to your old self \n"
     ]
    }
   ],
   "source": [
    "print(string.punctuation)\n",
    "def remove_punctuation(text):\n",
    "    text = text.replace('\\n', ' ') # also removing newline characters while removing punctuations\n",
    "    new_text = []\n",
    "    for char in text:\n",
    "        if char not in string.punctuation:\n",
    "            new_text.append(char)\n",
    "    return ''.join(new_text)\n",
    "\n",
    "data[\"no_punctuations\"] = \"\"\n",
    "for i, row in data.iterrows():\n",
    "    data.at[i, 'no_punctuations'] = remove_punctuation(row['text'])\n",
    "\n",
    "print(\"Plain Text:\\n\", data.text[0])\n",
    "print(\"\\n\")\n",
    "print(\"After removing punctuations:\\n\", data.no_punctuations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain Text:\n",
      " do you feel the pressure to perform and not rising to the occasion try v ia gr a your anxiety will be a thing of the past and you will be back to your old self \n",
      "\n",
      "\n",
      "After converting:\n",
      " do you feel the pressure to perform and not rising to the occasion try v ia gr a your anxiety will be a thing of the past and you will be back to your old self \n"
     ]
    }
   ],
   "source": [
    "def convert_lower_case(text):\n",
    "    new_text = []\n",
    "    for char in text:\n",
    "        new_text.append(char.lower())\n",
    "    return ''.join(new_text)\n",
    "\n",
    "data[\"lower_case\"] = \"\"\n",
    "for i, row in data.iterrows():\n",
    "    data.at[i, 'lower_case'] = convert_lower_case(row['no_punctuations'])\n",
    "\n",
    "print(\"Plain Text:\\n\", data.no_punctuations[0])\n",
    "print(\"\\n\")\n",
    "print(\"After converting:\\n\", data.lower_case[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(text):\n",
    "    text_without_numbers = re.sub(r'\\d', '', text)\n",
    "    return text_without_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_space(text):\n",
    "    text_without_spaces = re.sub(r'\\s{1,}', ' ', text)\n",
    "    text_without_spaces = text_without_spaces.strip()\n",
    "    return text_without_spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>new_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>do you feel the pressure to perform and not ri...</td>\n",
       "      <td>do you feel the pressure to perform and not ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>hi i've just updated from the gulus and i chec...</td>\n",
       "      <td>hi ive just updated from the gulus and i check...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>mega authenticv i a g r a discount pricec i a ...</td>\n",
       "      <td>mega authenticv i a g r a discount pricec i a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>hey billy it was really fun going out the othe...</td>\n",
       "      <td>hey billy it was really fun going out the othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>system of the home it will have the capabiliti...</td>\n",
       "      <td>system of the home it will have the capabiliti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      1  do you feel the pressure to perform and not ri...   \n",
       "1      0  hi i've just updated from the gulus and i chec...   \n",
       "2      1  mega authenticv i a g r a discount pricec i a ...   \n",
       "3      1  hey billy it was really fun going out the othe...   \n",
       "4      1  system of the home it will have the capabiliti...   \n",
       "\n",
       "                                            new_text  \n",
       "0  do you feel the pressure to perform and not ri...  \n",
       "1  hi ive just updated from the gulus and i check...  \n",
       "2  mega authenticv i a g r a discount pricec i a ...  \n",
       "3  hey billy it was really fun going out the othe...  \n",
       "4  system of the home it will have the capabiliti...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"new_text\"] = \"\"\n",
    "for i, row in data.iterrows():\n",
    "    data.at[i, 'new_text'] = remove_numbers(row['lower_case'])\n",
    "for i, row in data.iterrows():\n",
    "    data.at[i, 'new_text'] = remove_extra_space(row['new_text'])\n",
    "data.drop(['no_punctuations', 'lower_case'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>new_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>do you feel the pressure to perform and not ri...</td>\n",
       "      <td>do you feel the pressure to perform and not ri...</td>\n",
       "      <td>[do, you, feel, the, pressure, to, perform, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>hi i've just updated from the gulus and i chec...</td>\n",
       "      <td>hi ive just updated from the gulus and i check...</td>\n",
       "      <td>[hi, ive, just, updated, from, the, gulus, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>mega authenticv i a g r a discount pricec i a ...</td>\n",
       "      <td>mega authenticv i a g r a discount pricec i a ...</td>\n",
       "      <td>[mega, authenticv, i, a, g, r, a, discount, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>hey billy it was really fun going out the othe...</td>\n",
       "      <td>hey billy it was really fun going out the othe...</td>\n",
       "      <td>[hey, billy, it, was, really, fun, going, out,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>system of the home it will have the capabiliti...</td>\n",
       "      <td>system of the home it will have the capabiliti...</td>\n",
       "      <td>[system, of, the, home, it, will, have, the, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      1  do you feel the pressure to perform and not ri...   \n",
       "1      0  hi i've just updated from the gulus and i chec...   \n",
       "2      1  mega authenticv i a g r a discount pricec i a ...   \n",
       "3      1  hey billy it was really fun going out the othe...   \n",
       "4      1  system of the home it will have the capabiliti...   \n",
       "\n",
       "                                            new_text  \\\n",
       "0  do you feel the pressure to perform and not ri...   \n",
       "1  hi ive just updated from the gulus and i check...   \n",
       "2  mega authenticv i a g r a discount pricec i a ...   \n",
       "3  hey billy it was really fun going out the othe...   \n",
       "4  system of the home it will have the capabiliti...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [do, you, feel, the, pressure, to, perform, an...  \n",
       "1  [hi, ive, just, updated, from, the, gulus, and...  \n",
       "2  [mega, authenticv, i, a, g, r, a, discount, pr...  \n",
       "3  [hey, billy, it, was, really, fun, going, out,...  \n",
       "4  [system, of, the, home, it, will, have, the, c...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+', text)\n",
    "    return tokens\n",
    "\n",
    "data[\"tokens\"] = \"\"\n",
    "for i, row in data.iterrows():\n",
    "    data.at[i, 'tokens'] = tokenize(row['new_text'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(tokens):\n",
    "    ps = PorterStemmer()\n",
    "    return [ps.stem(word) for word in tokens]\n",
    "\n",
    "data['stemmed_tokens'] = data['tokens'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "\n",
    "data['lemmatized_tokens'] = data['stemmed_tokens'].apply(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>new_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>do you feel the pressure to perform and not ri...</td>\n",
       "      <td>do you feel the pressure to perform and not ri...</td>\n",
       "      <td>[do, you, feel, the, pressure, to, perform, an...</td>\n",
       "      <td>[do, you, feel, the, pressur, to, perform, and...</td>\n",
       "      <td>[do, you, feel, the, pressur, to, perform, and...</td>\n",
       "      <td>[feel, pressur, perform, rise, occas, tri, v, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>hi i've just updated from the gulus and i chec...</td>\n",
       "      <td>hi ive just updated from the gulus and i check...</td>\n",
       "      <td>[hi, ive, just, updated, from, the, gulus, and...</td>\n",
       "      <td>[hi, ive, just, updat, from, the, gulu, and, i...</td>\n",
       "      <td>[hi, ive, just, updat, from, the, gulu, and, i...</td>\n",
       "      <td>[hi, ive, updat, gulu, check, mirror, seem, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>mega authenticv i a g r a discount pricec i a ...</td>\n",
       "      <td>mega authenticv i a g r a discount pricec i a ...</td>\n",
       "      <td>[mega, authenticv, i, a, g, r, a, discount, pr...</td>\n",
       "      <td>[mega, authenticv, i, a, g, r, a, discount, pr...</td>\n",
       "      <td>[mega, authenticv, i, a, g, r, a, discount, pr...</td>\n",
       "      <td>[mega, authenticv, g, r, discount, pricec, l, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>hey billy it was really fun going out the othe...</td>\n",
       "      <td>hey billy it was really fun going out the othe...</td>\n",
       "      <td>[hey, billy, it, was, really, fun, going, out,...</td>\n",
       "      <td>[hey, billi, it, wa, realli, fun, go, out, the...</td>\n",
       "      <td>[hey, billi, it, wa, realli, fun, go, out, the...</td>\n",
       "      <td>[hey, billi, wa, realli, fun, go, night, talk,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>system of the home it will have the capabiliti...</td>\n",
       "      <td>system of the home it will have the capabiliti...</td>\n",
       "      <td>[system, of, the, home, it, will, have, the, c...</td>\n",
       "      <td>[system, of, the, home, it, will, have, the, c...</td>\n",
       "      <td>[system, of, the, home, it, will, have, the, c...</td>\n",
       "      <td>[system, home, capabl, link, far, know, within...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      1  do you feel the pressure to perform and not ri...   \n",
       "1      0  hi i've just updated from the gulus and i chec...   \n",
       "2      1  mega authenticv i a g r a discount pricec i a ...   \n",
       "3      1  hey billy it was really fun going out the othe...   \n",
       "4      1  system of the home it will have the capabiliti...   \n",
       "\n",
       "                                            new_text  \\\n",
       "0  do you feel the pressure to perform and not ri...   \n",
       "1  hi ive just updated from the gulus and i check...   \n",
       "2  mega authenticv i a g r a discount pricec i a ...   \n",
       "3  hey billy it was really fun going out the othe...   \n",
       "4  system of the home it will have the capabiliti...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [do, you, feel, the, pressure, to, perform, an...   \n",
       "1  [hi, ive, just, updated, from, the, gulus, and...   \n",
       "2  [mega, authenticv, i, a, g, r, a, discount, pr...   \n",
       "3  [hey, billy, it, was, really, fun, going, out,...   \n",
       "4  [system, of, the, home, it, will, have, the, c...   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0  [do, you, feel, the, pressur, to, perform, and...   \n",
       "1  [hi, ive, just, updat, from, the, gulu, and, i...   \n",
       "2  [mega, authenticv, i, a, g, r, a, discount, pr...   \n",
       "3  [hey, billi, it, wa, realli, fun, go, out, the...   \n",
       "4  [system, of, the, home, it, will, have, the, c...   \n",
       "\n",
       "                                   lemmatized_tokens  \\\n",
       "0  [do, you, feel, the, pressur, to, perform, and...   \n",
       "1  [hi, ive, just, updat, from, the, gulu, and, i...   \n",
       "2  [mega, authenticv, i, a, g, r, a, discount, pr...   \n",
       "3  [hey, billi, it, wa, realli, fun, go, out, the...   \n",
       "4  [system, of, the, home, it, will, have, the, c...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  [feel, pressur, perform, rise, occas, tri, v, ...  \n",
       "1  [hi, ive, updat, gulu, check, mirror, seem, li...  \n",
       "2  [mega, authenticv, g, r, discount, pricec, l, ...  \n",
       "3  [hey, billi, wa, realli, fun, go, night, talk,...  \n",
       "4  [system, home, capabl, link, far, know, within...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_wordsF = pd.read_csv('./DataSet/stop-words.csv')\n",
    "stop_words = []\n",
    "for word in stop_wordsF['0']:\n",
    "    stop_words.append(word)\n",
    "\n",
    "clean_txt = []\n",
    "for row in data['lemmatized_tokens']:\n",
    "    new_row = []\n",
    "    for token in row:\n",
    "        if(not token in stop_words):\n",
    "            new_row.append(token) \n",
    "    clean_txt.append(new_row)\n",
    "\n",
    "data['clean_text'] = clean_txt\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_set = set(word for text in data['clean_text'] for word in text)\n",
    "\n",
    "# for word in word_set:\n",
    "#     doc_count = sum(1 for doc in data['clean_text'] if word in doc)\n",
    "#     idf_table[word] = math.log(total_docs / (1 + doc_count))  # Adding 1 to avoid division by zero\n",
    "\n",
    "\n",
    "# tf = {}\n",
    "# def set_tf():\n",
    "#     tf = {}\n",
    "# def calculate_tf(word_set, data):\n",
    "\n",
    "#     for word in word_set:\n",
    "#         tf_list = []\n",
    "#         for doc in data:\n",
    "#             count = 0\n",
    "#             for term in doc:\n",
    "#                 if term == word:\n",
    "#                     count += 1\n",
    "#             term_freq = 0\n",
    "#             if count != 0:\n",
    "#                 term_freq = 1 + math.log(count, 2)\n",
    "#             tf_list.append(term_freq)\n",
    "#         tf[word] = tf_list\n",
    "\n",
    "#     tf_idf = pd.DataFrame(tf)\n",
    "#     return tf_idf\n",
    "\n",
    "# set_tf()\n",
    "# tf_idf  = calculate_tf(word_set, data['clean_text'])\n",
    "\n",
    "# def calculate_tf_idf(tf, idf_table):\n",
    "#     tf_idf = {}\n",
    "#     for word in tf.keys():\n",
    "#         tf_idf_list = [tf[word][i] * idf_table[word] for i in range(len(tf[word]))]\n",
    "#         tf_idf[word] = tf_idf_list\n",
    "\n",
    "#     tf_idf_table = pd.DataFrame(tf_idf)\n",
    "#     return tf_idf_table\n",
    "\n",
    "# tf_idf_table = calculate_tf_idf(tf, idf_table)\n",
    "# tf_idf_table.head()\n",
    "\n",
    "\n",
    "data['clean_text'] = data['clean_text'].apply(' '.join)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_vector = vectorizer.fit_transform(data['clean_text'])\n",
    "\n",
    "joblib.dump(vectorizer, './DataSet/vectorizer.joblib')\n",
    "\n",
    "save_npz('./DataSet/tfidf_vector_sparse.npz', tfidf_vector)\n",
    "\n",
    "# Load the TF-IDF vector from the sparse matrix file\n",
    "loaded_tfidf_vector = load_npz('./DataSet/tfidf_vector_sparse.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 180967)\t0.19095446010736283\n",
      "  (0, 144352)\t0.2245584127143744\n",
      "  (0, 15490)\t0.1905114060151016\n",
      "  (0, 150732)\t0.22980183445266128\n",
      "  (0, 200655)\t0.19189961501837136\n",
      "  (0, 9521)\t0.35078251480416944\n",
      "  (0, 83502)\t0.34316409850396096\n",
      "  (0, 94002)\t0.36898655703683647\n",
      "  (0, 205222)\t0.17170381445999983\n",
      "  (0, 142620)\t0.36152292356380067\n",
      "  (0, 172785)\t0.2698134356113022\n",
      "  (0, 152479)\t0.23325812845822724\n",
      "  (0, 159383)\t0.2817095193615477\n",
      "  (0, 70746)\t0.2084946037738639\n",
      "  (1, 117529)\t0.07159100365184952\n",
      "  (1, 38585)\t0.0410845619171498\n",
      "  (1, 205647)\t0.05984505668076646\n",
      "  (1, 193184)\t0.04019204476757009\n",
      "  (1, 117475)\t0.06958038014176232\n",
      "  (1, 170636)\t0.04936989953205303\n",
      "  (1, 59083)\t0.03787477655884909\n",
      "  (1, 210842)\t0.08859978061281074\n",
      "  (1, 62499)\t0.06149551631921449\n",
      "  (1, 36378)\t0.028113681694890626\n",
      "  (1, 178295)\t0.15265423999183125\n",
      "  :\t:\n",
      "  (101070, 122875)\t0.1330289585897811\n",
      "  (101070, 196530)\t0.21814110711562779\n",
      "  (101070, 58388)\t0.1331430838130512\n",
      "  (101070, 31787)\t0.17427209276530625\n",
      "  (101070, 17792)\t0.10958259549769504\n",
      "  (101070, 6799)\t0.09365785394560659\n",
      "  (101070, 183782)\t0.24506982132197308\n",
      "  (101070, 116553)\t0.23944608230433312\n",
      "  (101070, 167848)\t0.13197811154644262\n",
      "  (101070, 93049)\t0.15322950184267095\n",
      "  (101070, 76888)\t0.1238333620350588\n",
      "  (101070, 187159)\t0.18958161675845464\n",
      "  (101070, 115520)\t0.11377285650303237\n",
      "  (101070, 119707)\t0.13793938300142067\n",
      "  (101070, 48456)\t0.12368353140556473\n",
      "  (101070, 42741)\t0.11561817686438801\n",
      "  (101070, 172785)\t0.16208313499534543\n",
      "  (101071, 155895)\t0.7120750741452321\n",
      "  (101071, 119158)\t0.3001922052694983\n",
      "  (101071, 136648)\t0.2397267891239973\n",
      "  (101071, 113633)\t0.21432959772166557\n",
      "  (101071, 17857)\t0.3993288106528874\n",
      "  (101071, 167804)\t0.20563088742728827\n",
      "  (101071, 114591)\t0.2606255874841259\n",
      "  (101071, 201692)\t0.1724945247253828\n"
     ]
    }
   ],
   "source": [
    "print(loaded_tfidf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The term at index 114617 is: leasen\n"
     ]
    }
   ],
   "source": [
    "term_index = 114617\n",
    "term = vectorizer.get_feature_names_out()[term_index]\n",
    "\n",
    "print(f\"The term at index {term_index} is: {term}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
